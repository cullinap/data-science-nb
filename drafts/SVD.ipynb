{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD/PCA brainstorm\n",
    "\n",
    "1. Optimize: <br>\n",
    "    -$min_W,H ||V - WH||^2$ <br>\n",
    "    -s.t. $W^T W = I$ <br>\n",
    "    -restrict W to singular vectors of V: Looking for eigenvectors, <br>\n",
    "    -find best possible basis to represent V <br>\n",
    "    -V is an orthongonal matrix <br>\n",
    "    -can be non-negative <br>\n",
    "    -best possible matrix approximation for k <br>\n",
    "    -great for compression/filter out noise <br>\n",
    "    -violates non-negativety: bad for data analysis <br>\n",
    "    -basis vectors usually not interpretable big disadvantage in DS<br>\n",
    "    -PCA for any rank K will give most optimal data representation <br>\n",
    "    -does not mean it is optimal for interpretation <br>\n",
    "    -cannot assign any meaning to the basis vectors <br>\n",
    "    \n",
    "2. matrix factorization:\n",
    "    -extreme case reconstructing a matrix using the outer product of two\n",
    "    vectors: this would not be able to reconstruct the matrix exactly\n",
    "    -if we had a vector with the relative frequency of each vocab word\n",
    "    out of the total word count and another with the average words per\n",
    "    document, then the outer product would be close to approx the matrix\n",
    "    -if you increase it to two rows then you can have two clusters\n",
    "3. SVD:\n",
    "    -we expect word that appear more frequently in one topic to not\n",
    "    appear as frequently in another\n",
    "    -we expect the topics to be orthogonal\n",
    "    -SVD factorizaes a matrix into on ematrix w/orthogonal columsn and\n",
    "    one with orthoganl rows, along with a diag matirx which contains\n",
    "    the relative importance of each factor\n",
    "4. Truncated SVD\n",
    "    -Just interested in the vectors corresponding to the largest singular values\n",
    "    -Randomized SVD\n",
    "    -Not every matrix has an eigen decomposition, any matrix has a SVD\n",
    "    -SVD is a generalization of the eigendecomposition\n",
    "\n",
    "Machine Epsilon\n",
    "https://en.wikipedia.org/wiki/Machine_epsilon\n",
    "    \n",
    "QR algorithm\n",
    "-let's us find all the eigenvalues\n",
    "-QR algorithm v. QR decomposition:\n",
    "    -QR decomposition decomposes a matrix $A = QR$ into a set of orthonormal columns $Q$\n",
    "    and triangle matrix $R$\n",
    "-QR algorithm uses QR decomposition\n",
    "-Linear algebra\n",
    "    -two matrices are simliar if there exists a non-singular matrix X such that \n",
    "    $B = X^-1AX$\n",
    "    -If X is non-singular then $A$ and $X^-1$ have the same eigenvalues\n",
    "    -Schur factoriation of a matrix $A$ is a factorization $A = QTQ$\n",
    "    -Every square matrix has a Schur factorization\n",
    "    \n",
    "most basic QR algorithm\n",
    "    Q,R = A   # get the decomposition for A from previous iteration\n",
    "    A = R @ Q # new A to R x Q\n",
    "    \n",
    "converges to the Schur form of A (return something triangular\n",
    "Key: the QR algorithm constructs orthonormal bases for successive powers of A. And remeber the close relationship between powers of A and the eigen decomposition\n",
    "\n",
    "Rayleigh quotients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "A = np.random.rand(n,n)\n",
    "AT = A @ A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_qr(A, max_iter=50000):\n",
    "    Ak = np.copy(A) # copy of A can do in place\n",
    "    n = A.shape[0] # inti\n",
    "    QQ = np.eye(n) # intialize Q to be the identify\n",
    "    for k in range(max_iter):\n",
    "        Q, R = np.linalg.qr(Ak) # QR factorization using np.lin\n",
    "        Ak = R @ Q\n",
    "        QQ = QQ @ Q # running total of what happens when you mult Q*Q\n",
    "        if k % 10000 == 0:\n",
    "            print(Ak)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "    return Ak, QQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.61620451  0.17571725 -0.2760327 ]\n",
      " [ 0.08899736 -0.50693765  0.00870006]\n",
      " [ 0.01822226 -0.02387941 -0.01754127]]\n",
      "\n",
      "\n",
      "[[ 1.62066038 -0.07116801 -0.29666138]\n",
      " [ 0.         -0.51325018 -0.04576984]\n",
      " [ 0.          0.         -0.01568462]]\n",
      "\n",
      "\n",
      "[[ 1.62066038 -0.07116801 -0.29666138]\n",
      " [ 0.         -0.51325018 -0.04576984]\n",
      " [ 0.          0.         -0.01568462]]\n",
      "\n",
      "\n",
      "[[ 1.62066038 -0.07116801 -0.29666138]\n",
      " [ 0.         -0.51325018 -0.04576984]\n",
      " [ 0.          0.         -0.01568462]]\n",
      "\n",
      "\n",
      "[[ 1.62066038 -0.07116801 -0.29666138]\n",
      " [ 0.         -0.51325018 -0.04576984]\n",
      " [ 0.          0.         -0.01568462]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ak, Q = pure_qr(A) # approaches triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.62066038, -0.01568462, -0.51325018])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(A) # look at the eignencalues in the triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.eye(n), Q @ Q.T), np.allclose(np.eye(n), Q.T @ Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you start with a hessenberg form its faster --> use a phase I matrix to get to phase II QR matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gram-schmidt\n",
    "\n",
    "def cgs(A):\n",
    "    # get the shape in the form (m,n)\n",
    "    m,n = A.shape\n",
    "    # make two matrices filled with zeros\n",
    "    # Q = m x n and R = n x n\n",
    "    Q = np.zeros([m,n], dtype=np.float64)\n",
    "    R = np.zeros([n,n], dtype=np.float64)\n",
    "    \n",
    "    # loop n times \n",
    "    for j in range(n):\n",
    "        # set v = to a row in range(n)\n",
    "        v = A[:,j]\n",
    "        for i in range(j):\n",
    "            R[i,j] = np.dot(Q[:,i], A[:,j])\n",
    "            v -= (R[i,j] * Q[:,i])\n",
    "        R[j,j] = np.linalg.norm(v)\n",
    "        Q[:,j] = v / R[j,j]\n",
    "    return Q,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55358825, 0.53282953, 0.15715451, 0.90613389, 0.72968549])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55358825, 0.53282953, 0.15715451, 0.90613389, 0.72968549])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10926229 -0.24561691  0.13568     0.24442427 -0.23629114]\n",
      "[0. 0. 0. 0. 0.]\n",
      "0.0\n",
      "\n",
      "0.0\n",
      "\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# j = 1, i = 0\n",
    "print(A[:,1])\n",
    "print(Q[:,0])\n",
    "print(np.dot(Q[:,0], A[:,1]))\n",
    "RX = np.zeros([n,n], dtype=np.float64)\n",
    "RX[0,1] = np.dot(Q[:,0], A[:,1])\n",
    "print('')\n",
    "print(RX[0,1])\n",
    "print('')\n",
    "print(RX[0,1] * Q[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.array([\n",
    "    [1, 1, 2, 0, 1, 1],\n",
    "    [0, 0, 0, 1, 2, 1],\n",
    "    [1, 2, 3, 1, 3, 2],\n",
    "    [1, 0, 1, 0, 1, 1]\n",
    "], dtype=float)\n",
    "\n",
    "np.zeros(vectors.shape)[:, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt(X):\n",
    "    # a\n",
    "    O = np.zeros(X.shape) # vector space (the ground)\n",
    "    \n",
    "    # loop from 0 to the n dimension (6 in this case)\n",
    "    for i in range(X.shape[1]):\n",
    "        # orthogonalization\n",
    "        # b\n",
    "        vector = X[:, i] # grab a column\n",
    "        # c\n",
    "        space = O[:, :i] # grab a column and then next iteration grab another one plus previous one\n",
    "        # d\n",
    "        projection = vector @ space # dot product of vector * space\n",
    "        # e\n",
    "        vector = vector - np.sum(projection * space, axis=1)\n",
    "        \n",
    "        # normalization\n",
    "        # we are getting the magnitude - the euclidean distance L2 norm etc..\n",
    "        # but I don't think he is doing it here tho...\n",
    "        norm = np.sqrt(vector @ vector)\n",
    "        # g\n",
    "        vector /= abs(norm) < 1e-8 and 1 or norm\n",
    "        \n",
    "        # h\n",
    "        O[:, i] = vector \n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input X\n",
    "X = np.array([\n",
    "    [1, 1, 2, 0, 1, 1],\n",
    "    [0, 0, 0, 1, 2, 1],\n",
    "    [1, 2, 3, 1, 3, 2],\n",
    "    [1, 0, 1, 0, 1, 1]\n",
    "], dtype=float)\n",
    "\n",
    "# creat the vector space (the ground)\n",
    "O = np.zeros(X.shape); O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 2., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 2., 1.],\n",
       "       [1., 2., 3., 1., 3., 2.],\n",
       "       [1., 0., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peak at X\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1.])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab a column - first column in this case & name it vector\n",
    "vector = X[:, 0]\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(4, 0), dtype=float64)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab a column - we will grab a new col + each previous col \n",
    "# during each successive iteration\n",
    "# name this space \n",
    "\n",
    "space = O[:, :0]\n",
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply vector by space\n",
    "# in the first iteration it does nothing\n",
    "\n",
    "projection = vector @ space\n",
    "projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1.])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract the vector from the sum of projection * space\n",
    "# set to vector for the next iteration\n",
    "\n",
    "vector = vector - np.sum(projection * space, axis=1)\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize\n",
    "\n",
    "norm = np.sqrt(vector @ vector)\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the vector by the norm scalar\n",
    "\n",
    "vector /= abs(norm) < 1e-8 and 1 or norm \n",
    "\n",
    "# see if abs value < some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57735027, 0.        , 0.57735027, 0.57735027])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57735027, 0.        , 0.57735027, 0.57735027])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the first column of O equal to the vector\n",
    "\n",
    "O[:, 0] = vector\n",
    "O[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 2., 0.])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration 2a\n",
    "# grab a column - first column in this case & name it vector\n",
    "\n",
    "vector = X[:, 1]\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57735027],\n",
       "       [0.        ],\n",
       "       [0.57735027],\n",
       "       [0.57735027]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration 2b\n",
    "# grab a column - we will grab a new col + each previous col \n",
    "# during each successive iteration\n",
    "# name this space \n",
    "# on the second iteration it will be the first column\n",
    "\n",
    "space = O[:, :1]\n",
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.73205081])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration 2c\n",
    "# multiply vector by space\n",
    "# in the first iteration it does nothing\n",
    "\n",
    "projection = vector @ space\n",
    "projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.22044605e-16,  0.00000000e+00,  1.00000000e+00, -1.00000000e+00])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration 2d\n",
    "# subtract the vector from the sum of projection * space\n",
    "# set to vector for the next iteration\n",
    "\n",
    "vector = vector - np.sum(projection * space, axis=1)\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration 2e\n",
    "# normalize\n",
    "\n",
    "norm = np.sqrt(vector @ vector)\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.57009246e-16,  0.00000000e+00,  7.07106781e-01, -7.07106781e-01])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration 2f\n",
    "# divide the vector by the norm scalar if less than some values?\n",
    "\n",
    "vector /= abs(norm) < 1e-8 and 1 or norm \n",
    "\n",
    "# see if abs value < some values\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.57009246e-16,  0.00000000e+00,  7.07106781e-01, -7.07106781e-01])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration 2a\n",
    "# make the first column of O equal to the vector\n",
    "\n",
    "O[:, 1] = vector\n",
    "O[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 3., 1.])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration 3\n",
    "# grab a column - first column in this case & name it vector\n",
    "\n",
    "vector = X[:, 2]\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.57009246e-16, -1.57009246e-16],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 7.07106781e-01,  7.07106781e-01],\n",
       "       [-7.07106781e-01, -7.07106781e-01]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration 3\n",
    "# grab a column - we will grab a new col + each previous col \n",
    "# during each successive iteration\n",
    "# name this space \n",
    "# on the second iteration it will be the first column\n",
    "\n",
    "space = O[:, :2]\n",
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array([[3,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52000"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25 * 2080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52000.0259999935"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array([52000,52]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 NORM = hypotenuse\n",
    "(1**2 + 1**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j: 0 [0.55358825 0.53282953 0.15715451 0.90613389 0.72968549]\n",
      "\n",
      "j: 1 [ 0.10926229 -0.24561691  0.13568     0.24442427 -0.23629114]\n",
      "\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.10926229 -0.24561691  0.13568     0.24442427 -0.23629114]\n",
      "-------\n",
      "j: 2 [ 0.04011892 -0.06876398  0.70610188 -0.27579636  0.21018843]\n",
      "\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.04011892 -0.06876398  0.70610188 -0.27579636  0.21018843]\n",
      "-------\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.04011892 -0.06876398  0.70610188 -0.27579636  0.21018843]\n",
      "-------\n",
      "j: 3 [ 0.37329205  0.34310608  0.04525292 -0.16933323 -0.33321242]\n",
      "\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.37329205  0.34310608  0.04525292 -0.16933323 -0.33321242]\n",
      "-------\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.37329205  0.34310608  0.04525292 -0.16933323 -0.33321242]\n",
      "-------\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.37329205  0.34310608  0.04525292 -0.16933323 -0.33321242]\n",
      "-------\n",
      "j: 4 [ 0.24119826 -0.18678295 -0.11310704 -0.11553114  0.12123157]\n",
      "\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.24119826 -0.18678295 -0.11310704 -0.11553114  0.12123157]\n",
      "-------\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.24119826 -0.18678295 -0.11310704 -0.11553114  0.12123157]\n",
      "-------\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.24119826 -0.18678295 -0.11310704 -0.11553114  0.12123157]\n",
      "-------\n",
      "dot product: 0.0\n",
      "second R: 0.0\n",
      "v: [ 0.24119826 -0.18678295 -0.11310704 -0.11553114  0.12123157]\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "m,n = A.shape\n",
    "Q = np.zeros([m,n], dtype=np.float64)\n",
    "R = np.zeros([n,n], dtype=np.float64)\n",
    "\n",
    "# come up with a factorization - in QR factorizatoin\n",
    "\n",
    "# 34:00 m - youtube\n",
    "# create orthonormal columns of Q that will represent A\n",
    "# take the first column of A and have it normalized (first column of Q)\n",
    "# to find the second column of A you need to find\n",
    "# for each j calculate a single projection (v_j = P_j*a_j)\n",
    "# where P_j projects onto the space orthogonal to the span of q_1...q_j-1 (previous q's)\n",
    "\n",
    "# first column of Q is A normalized\n",
    "# second column of Q: take the second column of A, project it onto the first col of Q, subtract that off and that \n",
    "# will be your second column of Q once you normalize \n",
    "# each time you are going through and you want to subtract everything off that has been accounted for \n",
    "# as you are doing this you are creating these orthonormal columns of Q that represent your columns of A\n",
    "\n",
    "# the gram-schmidt process is like staring at a column at high noon\n",
    "# the column is the vector you are inputting to GS\n",
    "# the floor is vector space\n",
    "# the shadow is the projection\n",
    "# perpendicular is orthoganol\n",
    "# pushing it over until the shadow disppears is the gram-schmidt process\n",
    "# norms quantify vector magnitude\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for x,j in enumerate(range(n)):\n",
    "    v = A[:,j] # single projection a vector\n",
    "    print(f'j: {j} {v}')\n",
    "    print('')\n",
    "    #print(x, v)\n",
    "    for i in range(j):\n",
    "        print(f'dot product: {np.dot(Q[:,i], A[:,j])}')\n",
    "        R[i,j] = np.dot(Q[:,i], A[:,j])\n",
    "        print(f'second R: {R[i,j]}')\n",
    "        v -= (R[i,j] * Q[:,i])\n",
    "        print(f'v: {v}')\n",
    "        print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "A = np.random.rand(n,n)\n",
    "\n",
    "Q,R = cgs(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A, Q @ R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# practical QE (QR w/shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power iteration\n",
    "\n",
    "# start with a vector b, which maybe an approximation to the dominant eigenvector\n",
    "# or a random vector\n",
    "# start with random numbers for b\n",
    "\n",
    "b_k = np.random.rand(A.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the matrix by vector product Ab - the norm is the max of the resulting vector\n",
    "# looking to find the Eigenpair (Eigenvalue + Eigenvector)\n",
    "# will find the dominant eingenvalue\n",
    "b_kl_norm = np.linalg.norm(b_kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renormalize the vector\n",
    "b_k = b_kl / b_kl_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[0,1],[1,1]])\n",
    "b = np.array([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mutliply A*b\n",
    "\n",
    "Ab = A.dot(b)\n",
    "Ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize using vector max norm L^inf\n",
    "from numpy import inf\n",
    "\n",
    "Ab_norm = np.linalg.norm(Ab, inf)\n",
    "Ab_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find b2\n",
    "b2 = 0.5 * Ab\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart\n",
    "\n",
    "Ab2 = np.linalg.norm(A.dot(b2), inf)\n",
    "Ab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.666, 0.999])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.666 * A.dot(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2]) * 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "1\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "2\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "3\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "4\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "5\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "6\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "7\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "8\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "9\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "10\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "11\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "12\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "13\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "14\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "15\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "16\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "17\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "18\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "19\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "20\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "21\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "22\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "23\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "24\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "25\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "26\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "27\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "28\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "29\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "30\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "31\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "32\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "33\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "34\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "35\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "36\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "37\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "38\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "39\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "40\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "41\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "42\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "43\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "44\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "45\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "46\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "47\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "48\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "49\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "50\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "51\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "52\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "53\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "54\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "55\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "56\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "57\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "58\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "59\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "60\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "61\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "62\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "63\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "64\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "65\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "66\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "67\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "68\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "69\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "70\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "71\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "72\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "73\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "74\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "75\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "76\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "77\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "78\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "79\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "80\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "81\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "82\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "83\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "84\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "85\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "86\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "87\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "88\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "89\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "90\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "91\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "92\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "93\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "94\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "95\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "96\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "97\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n",
      "98\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [ 1. -1.]\n",
      "\n",
      "99\n",
      "eigenvalue: 1.0\n",
      "eigenvector: [-1.  1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how does this converge\n",
    "A = np.array([[0,1],[1,0]])\n",
    "b = np.array([-1,1])\n",
    "eigenvalue = []\n",
    "\n",
    "for i,x in enumerate(range(100)):\n",
    "    print(i)\n",
    "    Ab = A.dot(b)\n",
    "    Ab_norm = np.linalg.norm(Ab, inf)\n",
    "    print(f'eigenvalue: {Ab_norm}')\n",
    "    b_i = (1/Ab_norm) * Ab\n",
    "    print(f'eigenvector: {b_i}')\n",
    "    print('')\n",
    "    b = b_i\n",
    "    eigenvalue.append(Ab_norm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(eigenvalue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
